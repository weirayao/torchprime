model.embed_tokens.weight: [fsdp, null]
model.layers.*.self_attn.q_proj.weight: [fsdp, null]
model.layers.*.self_attn.k_proj.weight: [null, fsdp]
model.layers.*.self_attn.v_proj.weight: [null, fsdp]
model.layers.*.self_attn.o_proj.weight: [fsdp, null]
model.layers.*.feed_forward.experts.gate_up_proj: [fsdp, null, null]
model.layers.*.feed_forward.experts.down_proj:  [fsdp, null, null]
model.layers.*.feed_forward.router.weight: [fsdp, null]
model.layers.*.feed_forward.shared_expert.gate_proj.weight: [fsdp, null]
model.layers.*.feed_forward.shared_expert.up_proj.weight: [fsdp, null]
model.layers.*.feed_forward.shared_expert.down_proj.weight: [null, fsdp]
model.layers.*.input_layernorm.weight: [fsdp]
model.layers.*.post_attention_layernorm.weight: [fsdp]
model.norm.weight: [fsdp]
lm_head.weight: [fsdp, null]

# Activations
model.layers.*: [fsdp, null, null]
lm_head: [fsdp, null, null]
